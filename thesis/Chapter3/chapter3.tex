%❖ Chương này tập trung trình bày chi tiết những gì bạn
%làm
%❖ Mô tả chi tiết phương pháp thực hiện, giải pháp đề xuất, ứng dụng phát triển
%❖ Có thể đưa ra ví dụ minh họa để dẫn nhập
%❖ Nên phân thành các mục con
%   
%❖ Hướng nghiên cứu: Phương pháp đề xuất (Proposed Approach)
%o Cơ sở lý thuyết
%o Câu hỏi nghiên cứu, giả thuyết khoa học
%o Phương pháp/Thủ tục thực hiện nghiên cứu (procedure)
%o Đối tượng nghiên cứu
%o Môi trường (phần mềm, thư viện, máy móc, công cụ, v.v...)
%o Mô tả dữ liệu, quá trình thu thập dữ liệu
%o Độ đo để đánh giá (performance metrics)

\chapter{Phương pháp đề xuất}
\label{Chapter3}

%\begin{figure}
%    \centering
%    \includegraphics[width=\linewidth]{images/architecture.jpg}
%    \caption{Kiến trúc mồ hình sinh cử chỉ OHGesture}
%    \label{fig:architecture}
%\end{figure}

Trước tiên chúng tôi trình bày chúng tôi trình bày tổng quan của mô hình \ref{Overview},  và khung xương trong mỗi khung hình \ref{Skeleton} để hiểu được dữ liệu của mỗi khung hình. Từ đó chúng tôi đề xuất cách có thể trích xuất các đặc trưng về pha \ref{PeriodicAutoencoder} của mỗi khung hình để từ đó cách dùng mạng học sâu để học và điều khiển chuyển động của khung hình dựa trên pha \ref{MotionControllers}.

\section{Tổng quan mô hình}
\label{Overview}

Mô hình của chúng tôi sẽ lấy dữ liệu đầu vào ở khung hình thứ $i$ và dự đoán khung hình thứ $i+1$. Dữ liệu của mỗi khung hình là một chuỗi $\tau$ Chúng tôi sẽ trình bày

\subsection{Kiến trúc khung xương của mô hình}
\label{Skeleton}

Mỗi khung xương (skeleton) bao gồm $75$ khớp (joins) được đặt tên và minh hoạ ở hình \ref{fig:Skeleton}. 

\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[height=10cm]{images/Skeleton.png}
		\caption{Khung xương và tên của các khớp của một khung xương trong mỗi khung hình.}
		\label{fig:Skeleton}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[height=10cm]{images/MotionPastAndFuture.png}
		\caption{Chuỗi chuyển động của cử chỉ bao gồm 6 cử chỉ quá khứ và 6 cử chỉ tương lai.}
		\label{fig:MotionPastAndFuture}
	\end{subfigure}
\end{figure}


\subsection{Đầu vào và đầu ra của mô hình}
\label{System}

%\begin{figure}
%	\centering
%	\includegraphics[height=10cm]{images/MotionPastAndFuture.png}
%	\caption{Các tham số đã học cho pha.}
%	\label{fig:MotionPastAndFuture}
%\end{figure}


%\begin{figure}
%	\centering
%	\includegraphics[height=10cm]{images/MotionSeries.png}
%	\caption{Các tham số đã học.}
%	\label{fig:MotionSeries}
%\end{figure}

Hệ thống của chúng tôi là một mô hình chuỗi thời gian dự đoán các biến trạng thái của nhân vật, quả bóng, v.v. trong khung hình tiếp theo $i + 1$ dựa trên các biến trong khung hình hiện tại $i$. Các đầu vào và đầu ra được thiết kế sao cho hệ thống của chúng tôi có thể tạo ra các tương tác gần gũi giữa nhân vật và một đối tượng, một môi trường và một nhân vật khác. Một số biến cho điều khiển và điều kiện là hướng ứng dụng: ở đây, chúng tôi chủ yếu mô tả trong thiết lập bóng rổ, mặc dù khái niệm này là chung và có thể áp dụng cho các chuyển động khác như các thao tác của đối tượng và tương tác với môi trường. Để đào tạo, các đặc trưng Cartesian trong đầu vào và đầu ra được chuyển đổi vào hệ tọa độ gốc của nhân vật tại khung hình $i$ và $i + 1$, tương ứng. Tất cả các đặc trưng sống trong một cửa sổ chuỗi thời gian dài 1 giây, trong đó dữ liệu của 13 điểm mẫu đồng đều (6 điểm trong tương lai và 6 điểm trong quá khứ trong cửa sổ 1 giây, và một điểm cho khung hình hiện tại) được thu thập. Cách các giá trị được trích xuất từ dữ liệu ghi hình chuyển động được giải thích trong Phụ lục A.1.

\textbf{Inputs.} Vectơ đầu vào hoàn chỉnh $\textbf{X}_i$ tại khung hình $i$ bao gồm năm thành phần $\textbf{X}_i = \{ \textbf{X}^S_i, \textbf{X}^V_i, \textbf{X}^F_i, \textbf{X}^R_i, \textbf{X}^P_i \}$ trong đó mỗi thành phần được mô tả như dưới đây.

\begin{itemize}
	\item \textbf{Trạng thái Nhân vật}: \(\textbf{X}^\textbf{S}_i = \{p_i, r_i, v_i\}\) đại diện cho trạng thái của nhân vật của chúng tôi với \(B = 26\) xương tại khung hình hiện tại \(i\). Nó bao gồm các vị trí xương \(p_i \in \mathbb{R}^{3B}\), các xoay xương \(r_i \in \mathbb{R}^{6B}\) và vận tốc xương \(v_i \in \mathbb{R}^{3B}\), trong đó mỗi xoay xương được định nghĩa bằng cặp vector Cartesian tiến và lên của nó để tạo ra một không gian nội suy rõ ràng và liên tục.
	\item \textbf{Phase Chuyển Động Địa Phương} $\textbf{X}^{\mathcal{P}_i} = \Theta_i \in \mathbb{R}^{2KT}$ được đại diện bởi các vectơ pha 2D có biên độ thay đổi cho \(K = 5\) xương chính cho chân, tay và quả bóng, và được lấy mẫu dọc theo cửa sổ chuỗi thời gian từ quá khứ đến tương lai $T_{1s}^{-1s} = 13$. Các chi tiết về pha cấp xương được mô tả trong Phần 5.
	\item Third item
\end{itemize}

\textbf{Outputs} : Vector đầu ra $\textbf{Y}_i = \{ \textbf{Y}^S_i, \textbf{Y}^V_i, \textbf{Y}^F_i, \textbf{Y}^R_i, \textbf{Y}^P_i \}$ cho khung hình $i+1$

\section{Periodic Autoencoder}
\label{PeriodicAutoencoder}
%PERIODIC AUTOENCODER
	
\subsection{Network Structure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/BoneRotationSeries.png}
    \caption{Minh hoạ sự thay đổi góc quay của một khung xương}
    \label{fig:BoneRotationSeries}
\end{figure}

Để biến đổi không gian chuyển động thành một đa tạp pha học được, chúng tôi sử dụng kiến trúc autoencoder tích chập theo thời gian tương tự như Holden và cộng sự [2015]. Tuy nhiên, ngoài việc huấn luyện mô hình để tái tạo đầu vào, chúng tôi còn bắt buộc mỗi kênh của không gian tiềm ẩn phải có dạng hàm tuần hoàn, điều này cho phép chúng tôi học một biến pha cho mỗi kênh tiềm ẩn từ một tập hợp nhỏ các tham số. Kiến trúc mạng của chúng tôi được hiển thị trong Hình 2. Dữ liệu theo thời gian được chia thành các cửa sổ chồng chéo nhau với độ dài $N$ và cửa sổ thời gian trung tâm tương ứng là $T$. Với các đường cong chuyển động đầu vào, $X \in \mathbb{R}^{D \times N}$, trong đó $D$ là số bậc tự do của cơ thể và $N$ là số khung hình của $X$, chúng tôi huấn luyện một bộ mã hóa, $g$, sử dụng các tích chập 1D để học một nhúng không gian thấp hơn của chuyển động.


\begin{equation}
	\label{eq:encoder}
	\mathbf{L} = g( \textbf{X} )
\end{equation}

Giả sử $L \in \mathbb{R}^{M \times N}$, trong đó $M$ là số kênh tiềm ẩn, tức là số kênh pha mong muốn được trích xuất từ chuyển động. Chúng tôi áp đặt tính chu kỳ bằng cách tham số hóa mỗi đường cong tiềm ẩn trong $\mathbf{L}$ dưới dạng một hàm sóng hình sin, được xác định bởi các tham số biên độ ($\mathbf{A}$), tần số ($\mathbf{F}$), độ lệch ($\mathbf{B}$) và dịch pha ($\mathbf{S}$).

Để tính toán $\mathbf{A}, \mathbf{F}, \mathbf{B} \in \mathbb{R}^{M}$, chúng tôi sử dụng một lớp Fast Fourier Transform (FFT) thực khả vi. Chúng tôi áp dụng FFT cho mỗi kênh của $\mathbf{L}$ và tạo ma trận hệ số Fourier có chỉ mục bằng không $\mathbf{c} \in \mathbb{C}^{M \times (K+1)}, K=\left\lfloor \frac{N}{2} \right\rfloor$.

\begin{equation}
	\label{eq:fft}
	\mathbf{c}=F F T(\mathbf{L}), \quad \mathbf{p}_{i, j}=\frac{2}{N}\left|\mathbf{c}_{i, j}\right|^2
\end{equation}

trong đó $i$ là chỉ số kênh và $j$ là chỉ số cho các dải tần số. Các tham số tương ứng sau đó được cho bởi


\begin{equation}
	\label{eq:PhaseExtraction}
	\mathbf{A}_i=\sqrt{\frac{2}{N} \sum_{j=1}^K \mathbf{p}_{i, j}}, \quad \mathbf{F}_i=\frac{\sum_{j=1}^K\left(\mathbf{f}_j \cdot \mathbf{p}_{i, j}\right)}{\sum_{j=1}^K \mathbf{p}_{i, j}}, \quad \mathbf{B}_i=\frac{\mathbf{c}_{i, 0}}{N}
\end{equation}

trong đó $\textbf{f} = (0, \frac{1}{T}, \frac{2}{T}, \dots, \frac{K}{T})$ là một vector các tần số. Các phép toán này cung cấp các tham số hình dạng để xây dựng $M$ hàm tuần hoàn trong khoảng thời gian, nhưng chưa bao gồm yếu tố thời gian, tức là các dịch pha của các hàm này. Để có được tham số thời gian này, chúng tôi học một lớp fully-connected (FC) riêng biệt cho mỗi đường cong tiềm ẩn, lớp này chỉ dự đoán dịch pha có dấu $\textbf{S} \in \mathbb{R}^{M}$ tại khung trung tâm của $T$ thông qua một vector trung gian hai chiều:

\begin{equation}
	\label{eq:OffsetExtraction}
	\left(s_x, s_y\right)=F C\left(\mathrm{~L}_i\right), \quad \mathrm{S}_i=\operatorname{atan} 2\left(s_y, s_x\right)
\end{equation}

trong đó $i$ là chỉ số kênh.

Từ các tham số đã học được $F$, $A$, $B$ và $S$, cùng với khoảng thời gian $T$ đã biết, ta có thể tái tạo không gian tiềm ẩn được tham số hóa $\hat{L}$ dưới dạng nhiều hàm tuần hoàn có cùng dạng kích thước như không gian tiềm ẩn ban đầu bằng cách sử dụng hàm tham số hóa $f$:

\begin{equation}
	\label{eq:Sinusoidal}
	\hat{\mathbf{L}}=f(\mathcal{T} ; \mathbf{A}, \mathbf{F}, \mathbf{B}, \mathbf{S})=\mathbf{A} \cdot \sin (2 \pi \cdot(\mathbf{F} \cdot \mathcal{T}-\mathbf{S}))+\mathbf{B}
\end{equation}


Cuối cùng, mạng giải mã không gian tiềm ẩn đã được tham số hóa bằng các phép deconvolution 1D trong bộ giải mã $h$, để ánh xạ trở lại các đường cong chuyển động đầu vào ban đầu:

\begin{equation}
	\label{eq:Decoder}
	\textbf{Y} = h(\hat{\textbf{L}})
\end{equation}

Mạng được huấn luyện bằng hàm mất mát tái tạo giữa các đường cong chuyển động gốc và dự đoán:

\begin{equation}
	\label{eq:LossFunction}
	\mathcal{L} = \text{MSE}(\textbf{X}, \textbf{Y})
\end{equation}

Điều này buộc mạng phải học sự căn chỉnh thời gian của các tư thế trên các đoạn clip chuyển động khác nhau và gán một pha thay đổi cho mỗi khung hình mới của chuyển động theo một hướng nhất định. Để thấy điều này, hãy xem xét một đoạn chuyển động có khung trung tâm tại thời điểm $t$, được trích xuất từ một đoạn clip chuyển động dài hơn và được mã hóa để tạo ra $\hat{\textbf{L}}$. Các tham số $\textbf{A}$, $\textbf{F}$ và $\textbf{B}$ giới hạn hình dạng của các tín hiệu tuần hoàn và mạng phải học cách định vị các đường cong chính xác bằng $\textbf{S}$. Đối với một đoạn chuyển động có khung trung tâm tại thời điểm $t + 1$, được trích xuất từ cùng một đoạn clip chuyển động, chúng ta kỳ vọng rằng mọi thay đổi trong $\textbf{A}$, $\textbf{F}$ và $\textbf{B}$ sẽ rất nhỏ (xem Hình 3), vì vậy $\textbf{S}$ cần phải tiến triển để giữ cho không gian tiềm ẩn đồng bộ với chuyển động, vì cùng một bộ giải mã tích chập được sử dụng. Điều này có nghĩa là mô hình phải học cách dự đoán các vector 2D quay theo chiều kim đồng hồ để thay đổi các giá trị của biểu diễn tuần hoàn mà từ đó nó cần tái tạo các đường cong đầu vào.

Một cách khác để xây dựng đa tạp pha là học các tham số tuần hoàn trực tiếp bằng mạng thay vì sử dụng lớp FFT: chúng tôi đã thử nghiệm điều này nhưng không chỉ tham số pha mà cả biên độ và tần số cũng dao động rất nhiều theo thời gian, dẫn đến một đa tạp pha rất nhiễu. Việc học chuyển đổi tín hiệu sang miền tần số dường như không dễ dàng, và sử dụng lớp FFT làm ổn định quá trình học đáng kể.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{images/phase_bias_frequency_amplitudes_offsets.png}
	\caption{Các tham số đã học cho pha, biên độ, tần số và độ lệch cho một khoảng thời gian chuyển động cố định trong quá trình huấn luyện mạng để tái tạo chuyển động đầu vào, và từ đó có thể xây dựng đa tạp pha.}
	\label{fig:phase_bias_frequency_amplitudes_offsets}
\end{figure}

%$$
%\Gamma(x) = A sin (2 \pi (Fx - S)) + B
%$$

%Diffusion \cite{ho2020denoising} là mô hình được lấy cảm hứng từ mô hình khuếch tán các chất trong hóa học.

\subsection{Phase Manifold}
\label{sec:summary_diffusion}

%\begin{figure*}
%	\centering
%	\includegraphics[width=0.8\linewidth]{images/distribution.png}
%	\caption{Phân phối của các biên độ và tần số của các kênh pha đã học. Mỗi kênh được điều chỉnh cho một khoảng biên độ và tần số cụ thể để phân tích chuyển động, hoạt động như một tập hợp các bộ lọc thông dải đã học. Lưu ý rằng không có các khoảng tham số được định nghĩa trước cho mỗi kênh pha, mà chúng được trích xuất theo nhu cầu của mô hình.}
%	\label{fig:distribution}
%\end{figure*}

\begin{figure}
	\centering
	\includegraphics[height=10cm,width=\linewidth]{images/distribution.png}
	\caption{Phân phối của các biên độ và tần số của các kênh pha đã học. Mỗi kênh được điều chỉnh cho một khoảng biên độ và tần số cụ thể để phân tích chuyển động, hoạt động như một tập hợp các bộ lọc thông dải đã học. Lưu ý rằng không có các khoảng tham số được định nghĩa trước cho mỗi kênh pha, mà chúng được trích xuất theo nhu cầu của mô hình.}
	\label{fig:distribution}
\end{figure}

Chúng tôi sẽ mô tả cách mà đa tạp pha được hình thành bằng cách sử dụng các biến tiềm ẩn chu kỳ được tính toán với Mạng Tự Động Hóa Chu Kỳ. Sau khi huấn luyện mạng, các tham số chu kỳ cho một tập dữ liệu chuyển động không có cấu trúc có thể được tính toán cho mỗi khung hình bằng cách dịch Mạng Tự Động Hóa Chu Kỳ dọc theo các đường cong chuyển động. Các tham số chu kỳ đại diện cho tính chu kỳ cục bộ của các biến tiềm ẩn: sử dụng chúng, chúng tôi hình thành một đa tạp pha $\mathcal{P}$ có kích thước $\mathbb{R}^{2M}$, trong đó một mẫu tại khung hình $t$ được tính bằng

\begin{equation}
	\label{eq:phase_define}
	\mathcal{P}^{(t)}_{2i-1} = \textbf{A}^{(t)}_i \cdot \sin(2\pi \cdot \textbf{S}^{(t)}_i), \quad \mathcal{P}^{(t)}_{2i} = \textbf{A}^{(t)}_i \cdot \cos(2\pi \cdot \textbf{S}^{(t)}_i)
\end{equation}


\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{images/PhaseChannel.png}
	\caption{Phân phối của các biên độ và tần số của các kênh pha đã học. Mỗi kênh được điều chỉnh cho một khoảng biên độ và tần số cụ thể để phân tích chuyển động, hoạt động như một tập hợp các bộ lọc thông dải đã học. Lưu ý rằng không có các khoảng tham số được định nghĩa trước cho mỗi kênh pha, mà chúng được trích xuất theo nhu cầu của mô hình.}
	\label{fig:PhaseChannel}
\end{figure}


Các đặc trưng trong $\mathcal{P}$ mô tả tốt thời gian của khung hình trong chuyển động đầu vào $\textbf{X}$ và giúp rất nhiều trong việc căn chỉnh các chuyển động trong cùng một lớp hoặc giữa các lớp chuyển động khác nhau. Điều này có nghĩa là chúng có thể hoạt động hiệu quả như một đặc trưng đầu vào cho việc tổng hợp chuyển động thần kinh hoặc so khớp chuyển động, chúng tôi sẽ trình bày cách sử dụng và kết quả trong Mục 4 và Mục 5. Các biến pha của mười kênh trong một khoảng thời gian ngắn cho một đoạn clip chuyển động ví dụ được vẽ trong Hình 3. Có thể quan sát rằng mỗi kênh học các đặc trưng cho các tần số khác nhau, tương ứng với các tốc độ chuyển động khác nhau. Chúng tôi vẽ phân phối các biên độ và tần số của mỗi kênh trong Hình 4. Chúng tôi có thể quan sát rằng mỗi kênh pha học cách trích xuất các khoảng giá trị biên độ và tần số khác nhau trong các chuyển động. Hệ thống có thể mã hóa các chi tiết hoặc mẫu chuyển động khác nhau, điều này rất hữu ích cho việc căn chỉnh theo thời gian.

Khi có một chuỗi chuyển động, đặc trưng chu kỳ chuyển động mượt mà qua đa tạp pha. Vì biên độ và tần số của mỗi kênh pha có thể thay đổi theo thời gian, Mạng Tự Động Hóa Chu Kỳ có thể mã hóa các chuyển động không chu kỳ cũng như các chuyển động chu kỳ, chẳng hạn như chuyển tiếp từ một loại chuyển động này sang loại khác. Những chuyển tiếp không chu kỳ hoặc hành vi chuyển động như vậy có thể được quan sát dưới dạng biên độ tăng hoặc giảm cho các kênh khác nhau (ví dụ: một người đi bộ và bắt đầu vẫy tay), hoặc thay đổi không đồng bộ trong dịch pha hoặc tần số (ví dụ: chuyển tiếp giữa bước đi và bước chạy cho các loài bốn chân). Hình 5 minh họa những ví dụ như vậy nơi các pha có thể thể hiện các mẫu chu kỳ hoặc không chu kỳ trong suốt một đoạn clip chuyển động.



Lý do để định nghĩa đa tạp pha như trong phương trình (8) thay vì sử dụng riêng biệt tất cả các tham số như tần số, biên độ và pha là vì chúng tôi mong muốn các đặc trưng pha nhóm các hoạt ảnh theo cả không gian và thời gian. Các đặc trưng như tần số và biên độ vẫn gần như không thay đổi theo thời gian, và không giúp ích nhiều cho mục đích căn chỉnh. Biến đổi chúng thành một không gian hình cầu siêu thông qua phương trình (8) đạt được sự căn chỉnh không gian-thời gian như vậy, trong đó $A$ và $S$ định nghĩa điểm trong không gian đó và $F$ có thể được đại diện bởi một cửa sổ của các điểm như vậy. Phép biến đổi này cũng xây dựng một không gian nội suy liên tục: Trong khi các giá trị pha 1D là không liên tục và có thể trở nên không xác định nếu không có chuyển động nào được thực hiện, việc mã hóa chúng dưới dạng các vector 2D cho phép chuyển tiếp về gốc của đa tạp tại biên độ bằng không.

\subsection{Network Training}

Để huấn luyện Mạng Tự mã hóa Chu kỳ, chúng tôi sử dụng các quỹ đạo vận tốc khớp 3D làm đầu vào cho mạng, mỗi quỹ đạo được chuyển đổi vào không gian gốc của nhân vật [Holden et al. 2017]. Chúng tôi trừ đi giá trị trung bình dựa trên cửa sổ để căn giữa các đường cong chuyển động, nhưng không áp dụng bất kỳ phép tỷ lệ độ lệch chuẩn nào nhằm duy trì các khác biệt tương đối. Dữ liệu đầu vào bao gồm 60 khung hình (1 giây) mỗi khung ở quá khứ và tương lai xung quanh khung giữa với tần số 60 Hz. Điều này tạo ra một vector đầu vào $\textbf{X} \in \mathbb{R}^{3 \cdot J \times N}$, trong đó $J$ là số lượng khớp của nhân vật và $N$ (= 121) là số lượng mẫu thời gian.
Đối với bộ mã hóa $g$, chúng tôi sử dụng hai lớp tích chập, tạo ra một ánh xạ $(3 \cdot J \times N) \to (J \times N) \to (M \times N)$, để tính toán nhúng đường cong chuyển động. Mỗi lớp tích chập được theo sau bởi một phép chuẩn hóa theo lô (batch normalization) và hàm kích hoạt tanh. Vì chúng tôi thực hiện trực tiếp các phép toán trên không gian tiềm ẩn để trích xuất các tham số chu kỳ, chúng tôi nhận thấy rằng việc chuẩn hóa theo lô giúp ổn định quá trình huấn luyện cho nhiệm vụ này và giúp ngăn chặn sự phân phối không gian tiềm ẩn bị suy giảm hoặc mô hình bị quá khớp khi được huấn luyện quá lâu. Chúng tôi cũng áp dụng một phép chuẩn hóa theo lô cho vector dịch pha dự đoán trước khi tính toán góc có dấu của nó. Bộ giải mã $h$ lại bao gồm hai lớp tích chập để tính toán một ánh xạ $(M \times N) \to (J \times N) \to (3 \cdot J \times N)$, nhưng chỉ áp dụng phép chuẩn hóa theo lô và hàm kích hoạt tanh sau lớp giải chập đầu tiên và không áp dụng cho lớp đầu ra. Chúng tôi huấn luyện mạng của mình bằng bộ tối ưu AdamW [Loshchilov và Hutter 2019] trong 30 epoch, sử dụng tốc độ học và độ suy giảm trọng số đều là $10^{-4}$ và kích thước lô là 32. Việc huấn luyện trên GPU NVIDIA RTX 3090 thường mất chưa đầy một giờ cho các tác vụ nhỏ hơn.


\section{Motion Controllers}
\label{MotionControllers}

\subsection{Neural Motion Controller}

\begin{figure}
	\centering
	\includegraphics[]{images/PhaseManifold.png}
	\caption{Phân phối đặc trưng cho các miền chuyển động khác nhau trong không gian vận tốc (trên), không gian tiềm ẩn được học bởi mạng tích chập + mạng kết nối hoàn toàn (giữa) và không gian pha (dưới) được trực quan hóa bằng phép chiếu PCA 2D. Mỗi màu đại diện cho các tư thế từ một chuỗi chuyển động duy nhất mà được kết nối theo thời gian.}
	\label{fig:PhaseManifold}
\end{figure}


Đối với bộ điều khiển dựa trên mạng nơ-ron, chúng tôi phát triển một mô hình chuỗi thời gian dự đoán tư thế trong khung hình hiện tại dựa trên khung hình trước đó và các điều khiển của người dùng hiện tại. Mô hình được huấn luyện theo cách giám sát sử dụng dữ liệu ghi hình chuyển động. Chúng tôi sử dụng khung Mixture-of-Experts pha trộn trọng số tương tự như [Starke et al. 2020; Zhang et al. 2018], nhưng thay vì sử dụng các vận tốc hoặc pha địa phương dựa trên tiếp xúc làm đầu vào cho mạng gating, chúng tôi sử dụng các vectơ pha trên mặt phẳng pha (tức là, Eq. (8)) làm các đặc trưng đầu vào để tạo ra các chuyển động theo cách tự hồi quy. Việc cung cấp đặc trưng pha làm đầu vào giúp hệ thống căn chỉnh dữ liệu chuyển động theo dòng thời gian và cho phép nhân vật chuyển tiếp giữa các chuyển động một cách thực tế như chúng tôi đã trình bày trong Mục 5.

Hệ thống tự hồi quy cập nhật trạng thái pha của nhân vật cũng như chuyển động của nó. Hệ thống đầu tiên dự đoán các vectơ pha tiếp theo $P_{t+\Delta t}$, các biên độ $A_{t+\Delta t}$ và tần số $F_{t+\Delta t}$. Thay vì sử dụng trực tiếp các vectơ pha đã dự đoán, nó được cập nhật như sau:

\begin{equation}
	\label{eq:PhaseVector}
	\mathcal{P}_{t+\Delta t}^{\prime}=A_{t+\Delta t} \cdot I\left(R(\theta) \cdot \mathcal{P}_t, \mathcal{P}_{t+\Delta t}\right), \quad \theta=\Delta t \cdot 2 \pi \cdot F_{t+\Delta t}
\end{equation}

trong đó $\Delta t$ là thời gian delta của khung hình, $R$ là ma trận quay 2D, và \(I\) là nội suy tuyến tính hình cầu với trọng số 0.5 để cho phép pha trộn góc pha và độ lớn một cách riêng biệt. Việc cập nhật pha theo cách này buộc tần số tiến triển pha theo hướng mà mạng nơ-ron đã dự đoán. Tần số là một giá trị dương đồng nhất dễ dự đoán và giữ cho mạng di chuyển qua không gian pha theo một cách một chiều (xem Hình 6). Sơ đồ này ngăn chuyển động trở nên cứng nhắc hoặc bị kẹt theo thời gian, điều này là một vấn đề phổ biến được quan sát thấy đối với các bộ điều khiển nhân vật dựa trên dữ liệu.

Mạng gating chuyên gia học cách pha trộn 8 bộ trọng số chuyên gia và bao gồm hai lớp ẩn có kích thước 128. Mạng tạo chuyển động sử dụng hai lớp ẩn có kích thước 512. Tỉ lệ dropout được đặt thành 0.3, kích thước lô là 32, và cả tốc độ học và suy giảm trọng số đều được khởi tạo là \(10^{-4}\). Chúng tôi sử dụng bộ tối ưu AdamWR [Loshchilov và Hutter 2019] với lịch trình giảm nhiệt cosin và đặt số lần khởi động lại là 10, hệ số khởi động lại là 2.0, và huấn luyện mô hình trong 150 epoch. Việc huấn luyện mỗi mô hình yêu cầu từ 12 đến 48 giờ. Mạng được triển khai trong PyTorch và tạo ra một tệp ONNX có thể được chạy trong Unity để suy diễn bằng cách sử dụng thư viện Barracuda của nó.


\subsection{Motion Matching}

Trong bối cảnh của việc khớp chuyển động, các pha có thể được sử dụng theo cách tương tự như đối với các mạng nơ-ron và không yêu cầu thay đổi trong các quy trình công việc điển hình cho việc khớp chuyển động. Sự khác biệt chính là thay vì khớp các đặc trưng tư thế hoặc vận tốc có chiều cao hơn của trạng thái nhân vật hiện tại, hệ thống khớp các vectơ pha có chiều thấp hơn để tìm kiếm tư thế ở khung hình tiếp theo dựa trên các tín hiệu điều khiển của người dùng, chẳng hạn như quỹ đạo gốc. Chúng tôi trực quan hóa các đặc trưng pha và các đặc trưng vận tốc cho các chuyển động khác nhau trong Hình 6 (xem Mục 5.1 để biết thêm chi tiết). Khoảng cách Euclid giữa các điểm lân cận trong không gian pha liền kề với nhau là đồng nhất (hàng dưới cùng), điều này có nghĩa là các tư thế được khớp bởi việc khớp chuyển động sẽ có sự khác biệt tương tự về thời gian. Điều này cho phép

tổng hợp các chuyển tiếp chuyển động mượt mà và thực tế hơn với ít điều chỉnh tham số hơn, điều này không dễ dàng xảy ra khi khớp các đặc trưng tư thế Cartesian (hàng trên cùng) cần được chọn thủ công cho các khớp cụ thể (ví dụ: chân cho chuyển động) hoặc yêu cầu thêm bộ lọc.





%\subsection{Quá trình gây nhiễu (forward diffusion process)}
%
%Cho dữ liệu $x_{0}$ là được lấy từ dữ liệu thật $x_{0} \sim q(x)$, với mỗi bước ta sẽ thêm nhiễu vào đầu vào $x_{0}$ với tỷ lệ nhiều và ảnh gốc được kiểm soát bằng hệ số $\beta$:
%
%
%\begin{equation}
%	\label{eq:addgaussian}
%	\mathbf{x}_t = \sqrt{1 - \beta_t}\mathbf{x}_{t-1} + \sqrt{\beta_t} \boldsymbol{\epsilon}_{t-1}
%\end{equation}
%
%Trong đó, quá trình gây nhiễu từ $1 \to T$, với mỗi bước $t$ quá trình thêm nhiễu $\epsilon$ được điều khiển bằng $\beta_t$ theo phương sai $\{\beta_t \in (0, 1)\}_{t=1}^T$:
%
%\begin{equation}
%	\label{eq:forward_diffusion_process}
%	\begin{aligned}
%		q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) &= \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I}) \quad \\
%		q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) &= \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})
%	\end{aligned}
%\end{equation}
%
%Mục tiêu ở bước $t$ của hệ số $\sqrt{1 - \beta_t}$ và $\beta_t$ là để lần lượt giảm tỷ lệ của ảnh gốc $x_t$ và tăng dần nhiễu  $\boldsymbol{\epsilon}_{t-1}$, vì vậy $\beta_1 < \beta_2 < \dots < \beta_T$. Khi $T \to \infty$ thì $x_{T}$ sẽ hoàn toàn nhiễu (Isotropic Gaussian Distribution).
%
%
%Vì nhiễu $\boldsymbol{\epsilon}_{t-1}, \boldsymbol{\epsilon}_{t-2}, \dots \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ luôn luôn là phân phối chuẩn, và cho trước trong mọi bước $t$, nên ta có thể dễ dàng truy ngược được $x_t$ từ $x_0$. Bằng cách đặt $\alpha_t = 1 - \beta_t$ và $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$, từ công thức \ref{eq:addgaussian}, ta có hàm forward diffusion viết lại theo $\alpha$ như sau:
%
%\begin{equation}
%	\label{eq:tracexzero}
%	\begin{aligned}
%		\mathbf{x}_t 
%		&= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1} \\
%		&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2}
%		&= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon} \\
%		q(\mathbf{x}_t \vert \mathbf{x}_0) &= \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})
%	\end{aligned}
%\end{equation}
%
%
%\subsection{Quá trình khử nhiễu (denoising process)}
%\label{subsection:denoising_process}
%
%Quá trình khử nhiễu $p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)$  ở bước thứ $t$ từ $T \to 1$ được bắt đầu từ $x_T$ là hoàn toàn nhiễu $\mathcal{N} (\mathbf{0}, \mathbf{I})$. Ta sẽ dùng một neural network $f_{\theta} (x_t, t)$ để dự đoán nhiễu $\hat{\epsilon} = f_{\theta}(x_t, t)$ đã được thêm vào để được $x_{t-1}$ từ $x_t$.
%. Quá trình khử nhiễu có trung bình $\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = {\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}}  f_\theta(\mathbf{x}_t, t) \Big)}$ và độ lệch chuẩn $\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)$ như sau:
%
%
%%\begin{equation} \mathrm{d}\mathbf{x} = [\mathbf{f}(\mathbf{x}, t) - g^2(t) \nabla_\mathbf{x} \log p_t(\mathbf{x})]\mathrm{d}t + g(t) \mathrm{d} \mathbf{w}.\label{rsde} \end{equation}
%
%% bằng cách lấy ảnh bị nhiễu trừ đi nhiễu dự đoán
%
%\begin{equation}
%	\label{eq:denoising_process}
%	\begin{aligned}
%		p_\theta(\mathbf{x}_{0:T})
%		&= p(\mathbf{x}_T) \prod^T_{t=1} p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) \\
%		p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) &= \mathcal{N}(\mathbf{x}_{t-1};  \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
%	\end{aligned}
%\end{equation}
%
%%Ta viết lại hàm denoising từ công thức \ref{eq:denoising_process}  theo $\alpha$ như sau:
%%$$
%%x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\sqrt{1 - \alpha_t}}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_{\theta}(x_t, t) \right) + \sqrt{1 - \alpha_t} \tilde{\epsilon}_t
%%$$
%
%
%%\begin{equation}
%%	\label{eq:denoising_alpha}
%%	\begin{aligned}
%	%	p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) &= \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
%	%\end{aligned} \\
%	% \bar{\boldsymbol{\mu}}_t (x_t, t) = \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)
%	%\end{equation}
%	
%	\subsection{Hàm mất mát $\mathcal{L}$ của mô hình diffusion}
%	
%	Như đã trình bày ở trên, mô hình diffusion sẽ học trọng số $\theta$ của hàm dự đoán lỗi $f_{\theta} (x_t, t)$. Trong quá trình denoising, ta sẽ tối ưu độ lỗi giữa nhiễu dự đoán $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$ và nhiễu thực tế $\boldsymbol{\epsilon}_t$. Với mỗi bước thứ $t$ ta sẽ tối ưu hàm loss $\mathcal{L}_{t}$ để thu được trọng số $\theta$.
%	
%	\begin{equation}
%		\label{eq:diffusion_loss}
%		\begin{aligned}
%			\mathcal{L}_t
%			&= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
%			&= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big]
%		\end{aligned}
%	\end{equation}
%	
%	Thay vì dùng neuron network để dự đoán phân bố của dữ liệu theo như hình \ref{fig:basic_diffusion}, mô hình diffusion sẽ dự đoán độ lỗi được thêm vào trong ảnh ở bước thứ $t$, với mỗi $t$ bước ta sẽ cần tối ưu hàm mất mát $\mathcal{L}_t$, hàm mất mát của mỗi bước sẽ tối ưu độ lỗi giữa nhiễu dự đoán $\hat{\epsilon_t}$ và nhiễu nhãn $\epsilon_t$ được thêm vào. Với $f_{\theta}(x_{t-1}, t)$ là một mô hình Unet dùng để mã hoá và giải mã dữ liệu để dự đoán nhiễu đã thêm vào dữ liệu.
%	
%	%Hàm loss
%	
%	
%	\subsection{Quá trình dự đoán trong mô hình diffusion}
%	
%	Sau khi thu được trọng số $\theta'$, ta sẽ dùng hàm denoising để khử nhiễu từ nhiễu $x_T \sim \mathcal{N} (\mathbf{0}, \mathbf{I})$.
%	Quá trình biến đổi từ nhiễu hoàn toàn $x_{T}$ sang dự đoán $\hat{x_0}$ như sau:
%	%với $t$ là một vector đã được nhúng vị trí bằng thuật toán nhúng
%	
%	\begin{equation}
%		\label{eq:adddenoising}
%		x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1- \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} f_{\theta'}(x_t, t) \right) + \sqrt{1 - \alpha_t} \tilde{\epsilon}_t
%	\end{equation}
%	
%	Lưu ý rằng $\tilde{\epsilon}_t$ là nhiễu cố định $\epsilon_t$ giống với nhiễu trong quá trình forward diffusion \ref{subsection:denoising_process} ở công thức  \ref{eq:addgaussian}.
%
	
% GAT
%\input{Chapter3/ohgesture}


