\section{Training Procedure}

\begin{algorithm}[h]
	\caption{Training in DeepGesture}
	\label{alg:trainingDeepGesture}
	\setlength{\baselineskip}{10pt}
	\begin{enumerate}
		\item Pre-compute $\gamma$, $\sqrt{\alpha_t}$, $\sqrt{1-\alpha_t}$, $\sqrt{\bar{\alpha}_t}$, and random noise $\boldsymbol{\epsilon}_t$ for each timestep $t: 1 \rightarrow T$. Define the noise schedule $\{\alpha_t \in (0,1)\}_{t=1}^T$.
		\item Sample the initial label $\mathbf{x}_0$ from the normalized data distribution.
		\item Randomly generate Bernoulli masks
		$c_{1} = [ \mathbf{s}, \mathbf{e_1}, \mathbf{a}, \mathbf{v} ]$,
		$c_{2} = [ \mathbf{s}, \mathbf{e_2}, \mathbf{a}, \mathbf{v} ]$, or
		$c_{2} = [ \varnothing, \varnothing, \mathbf{a}, \mathbf{v} ]$.
		\item Add noise to obtain the noisy gesture $\mathbf{x}_t$:
		\[
		\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}_t.
		\]
		\item Sample $t$ \textbf{uniformly} from $[1, T]$.
		\item Given $\mathbf{x}_t$, $t$, and masks $c_1$, $c_2$, predict the gesture sequence:
		\[
		\hat{\mathbf{x}}_{0\,\gamma,c_{1},c_{2}}
		= \gamma\, G_{\theta}(\mathbf{x}_{t}, t, c_{1})
		+ (1-\gamma)\, G_{\theta}(\mathbf{x}_{t}, t, c_{2}).
		\]
		\item Compute the loss and gradient to update $\theta$:
		\[
		\mathcal{L}^t
		= \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}_t}
		\bigl[\operatorname{HuberLoss}(\mathbf{x}_0, \hat{\mathbf{x}}_0)\bigr].
		\]
		\item Repeat from step 6 until convergence, obtaining the optimal parameters $\theta'$.
	\end{enumerate}
\end{algorithm}

\autoref{alg:trainingDeepGesture} trains the DeepGesture model by first computing the required values and hyper-parameters -- 	$\gamma$, $\sqrt{\alpha_t}$, $\sqrt{1-\alpha_t}$, $\sqrt{\bar{\alpha}_t}$, and $\boldsymbol{\epsilon}_t$ -- for every timestep $t$ (1 â€¦ $T$).  
The initial label $\mathbf{x}_0$, representing the ground-truth gesture, is drawn from the normalized data distribution.  
Random Bernoulli masks $c_1$ and $c_2$ emulate different conditions (gesture, emotion, speech, or text), with one mask possibly lacking emotion information.  
Noise is then added to create the noisy gesture $\mathbf{x}_t$.  
A timestep $t$ is sampled uniformly, and $\mathbf{x}_t$ with the masks is fed into the model to predict the original gesture sequence as a weighted combination of conditional outputs.  
The Huber loss between ground-truth and prediction is used to update $\theta$.  
This cycle repeats until the model converges, yielding the optimal parameters $\theta'$.



